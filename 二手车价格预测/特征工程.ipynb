{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程（Feature Engineering）\n",
    "对特征进行进一步分析，并对数据进行处理。常见的特征工程包括：异常值处理、缺失值处理、数据分桶、特征处理、特征构造、特征筛选及降维等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据及背景\n",
    "https://tianchi.aliyun.com/competition/entrance/231784/information（阿里天池-零基础入门数据挖掘）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/p1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='p1.png', width=500, height=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src='p1.png', width=500, height=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 颜色\n",
    "color = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('used_car_train_20200313.csv',sep = ' ')\n",
    "df_test = pd.read_csv('used_car_testB_20200421.csv',sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将测试集和训练集和并 \n",
    "df_train[\"oringin\"]=\"train\"\n",
    "df_test[\"oringin\"]=\"test\"\n",
    "original_data = pd.concat([df_train,df_test],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>regDate</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>...</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>v_9</th>\n",
       "      <th>v_10</th>\n",
       "      <th>v_11</th>\n",
       "      <th>v_12</th>\n",
       "      <th>v_13</th>\n",
       "      <th>v_14</th>\n",
       "      <th>oringin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>20040402</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101988</td>\n",
       "      <td>0.129549</td>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.097462</td>\n",
       "      <td>-2.881803</td>\n",
       "      <td>2.804097</td>\n",
       "      <td>-2.420821</td>\n",
       "      <td>0.795292</td>\n",
       "      <td>0.914762</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>20030301</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.135731</td>\n",
       "      <td>0.026597</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>-4.900482</td>\n",
       "      <td>2.096338</td>\n",
       "      <td>-1.030483</td>\n",
       "      <td>-1.722674</td>\n",
       "      <td>0.245522</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>20040403</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114912</td>\n",
       "      <td>0.165147</td>\n",
       "      <td>0.062173</td>\n",
       "      <td>0.027075</td>\n",
       "      <td>-4.846749</td>\n",
       "      <td>1.803559</td>\n",
       "      <td>1.565330</td>\n",
       "      <td>-0.832687</td>\n",
       "      <td>-0.229963</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>19960908</td>\n",
       "      <td>109.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.121964</td>\n",
       "      <td>0.033395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.509599</td>\n",
       "      <td>1.285940</td>\n",
       "      <td>-0.501868</td>\n",
       "      <td>-2.438353</td>\n",
       "      <td>-0.478699</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>20120103</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073205</td>\n",
       "      <td>0.091880</td>\n",
       "      <td>0.078819</td>\n",
       "      <td>0.121534</td>\n",
       "      <td>-1.896240</td>\n",
       "      <td>0.910783</td>\n",
       "      <td>0.931110</td>\n",
       "      <td>2.834518</td>\n",
       "      <td>1.923482</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SaleID    name   regDate  model  brand  bodyType  fuelType  gearbox  power  \\\n",
       "0       0     736  20040402   30.0      6       1.0       0.0      0.0     60   \n",
       "1       1    2262  20030301   40.0      1       2.0       0.0      0.0      0   \n",
       "2       2   14874  20040403  115.0     15       1.0       0.0      0.0    163   \n",
       "3       3   71865  19960908  109.0     10       0.0       0.0      1.0    193   \n",
       "4       4  111080  20120103  110.0      5       1.0       0.0      0.0     68   \n",
       "\n",
       "   kilometer  ...       v_6       v_7       v_8       v_9      v_10      v_11  \\\n",
       "0       12.5  ...  0.101988  0.129549  0.022816  0.097462 -2.881803  2.804097   \n",
       "1       15.0  ...  0.121004  0.135731  0.026597  0.020582 -4.900482  2.096338   \n",
       "2       12.5  ...  0.114912  0.165147  0.062173  0.027075 -4.846749  1.803559   \n",
       "3       15.0  ...  0.110300  0.121964  0.033395  0.000000 -4.509599  1.285940   \n",
       "4        5.0  ...  0.073205  0.091880  0.078819  0.121534 -1.896240  0.910783   \n",
       "\n",
       "       v_12      v_13      v_14  oringin  \n",
       "0 -2.420821  0.795292  0.914762    train  \n",
       "1 -1.030483 -1.722674  0.245522    train  \n",
       "2  1.565330 -0.832687 -0.229963    train  \n",
       "3 -0.501868 -2.438353 -0.478699    train  \n",
       "4  0.931110  2.834518  1.923482    train  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e386f39cd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_data.boxplot(['power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"这里包装了一个异常值处理的代码，可以随便调用\"\"\"\n",
    "def outliers_proc(data, col_name, scale=3):\n",
    "    \"\"\"\n",
    "        用于截尾异常值， 默认用box_plot(scale=3)进行清洗\n",
    "        param:\n",
    "            data：接收pandas数据格式\n",
    "            col_name: pandas列名\n",
    "            scale: 尺度\n",
    "    \"\"\"\n",
    "    data_col = data[col_name]\n",
    "    Q1 = data_col.quantile(0.25) # 0.25分位数\n",
    "    Q3 = data_col.quantile(0.75)  # 0,75分位数\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    data_col[data_col < Q1 - (scale * IQR)] = Q1 - (scale * IQR)\n",
    "    data_col[data_col > Q3 + (scale * IQR)] = Q3 + (scale * IQR)\n",
    "\n",
    "    return data[col_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data['power'] = outliers_proc(original_data, 'power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e395841a60>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_data.boxplot(['power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_proc(data, col_name, scale=3):\n",
    "    \"\"\"\n",
    "    用于清洗异常值，默认用 box_plot（scale=3）进行清洗\n",
    "    :param data: 接收 pandas 数据格式\n",
    "    :param col_name: pandas 列名\n",
    "    :param scale: 尺度\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    def box_plot_outliers(data_ser, box_scale):\n",
    "        \"\"\"\n",
    "        利用箱线图去除异常值\n",
    "        :param data_ser: 接收 pandas.Series 数据格式\n",
    "        :param box_scale: 箱线图尺度，\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        iqr = box_scale * (data_ser.quantile(0.75) - data_ser.quantile(0.25))\n",
    "        val_low = data_ser.quantile(0.25) - iqr\n",
    "        val_up = data_ser.quantile(0.75) + iqr\n",
    "        rule_low = (data_ser < val_low)\n",
    "        rule_up = (data_ser > val_up)\n",
    "        return (rule_low, rule_up), (val_low, val_up)\n",
    "\n",
    "    data_n = data.copy()\n",
    "    data_series = data_n[col_name]\n",
    "    rule, value = box_plot_outliers(data_series, box_scale=scale)\n",
    "    index = np.arange(data_series.shape[0])[rule[0] | rule[1]]\n",
    "    print(\"Delete number is: {}\".format(len(index)))\n",
    "    data_n = data_n.drop(index)\n",
    "    data_n.reset_index(drop=True, inplace=True)\n",
    "    print(\"Now column number is: {}\".format(data_n.shape[0]))\n",
    "    index_low = np.arange(data_series.shape[0])[rule[0]]\n",
    "    outliers = data_series.iloc[index_low]\n",
    "    print(\"Description of data less than the lower bound is:\")\n",
    "    print(pd.Series(outliers).describe())\n",
    "    index_up = np.arange(data_series.shape[0])[rule[1]]\n",
    "    outliers = data_series.iloc[index_up]\n",
    "    print(\"Description of data larger than the upper bound is:\")\n",
    "    print(pd.Series(outliers).describe())\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 7))\n",
    "    sns.boxplot(y=data[col_name], data=data, palette=\"Set1\", ax=ax[0])\n",
    "    sns.boxplot(y=data_n[col_name], data=data_n, palette=\"Set1\", ax=ax[1])\n",
    "    return data_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e3871e68e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_data['power'].hist()\n",
    "#power这个特征的分布也不错了，所以就没再进一步处理power，至于其他的数值型是不是需要截尾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺失值处理\n",
    "关于缺失值处理的方式， 有几种情况：\n",
    "\n",
    "不处理（这是针对xgboost等树模型），有些模型有处理缺失的机制，所以可以不处理\n",
    "\n",
    "如果缺失的太多，可以考虑删除该列\n",
    "\n",
    "插值补全（均值，中位数，众数，建模预测，多重插补等）\n",
    "\n",
    "分箱处理，缺失值一个箱。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 删除重复值\n",
    "# #data.drop_duplicates()\n",
    "# # dropna()可以直接删除缺失样本，但是有点不太好\n",
    "\n",
    "# # 填充固定值\n",
    "# train_data.fillna(0, inplace=True) # 填充 0\n",
    "# data.fillna({0:1000, 1:100, 2:0, 4:5})   # 可以使用字典的形式为不用列设定不同的填充值\n",
    "\n",
    "# train_data.fillna(train_data.mean(),inplace=True) # 填充均值\n",
    "# train_data.fillna(train_data.median(),inplace=True) # 填充中位数\n",
    "# train_data.fillna(train_data.mode(),inplace=True) # 填充众数\n",
    "\n",
    "# train_data.fillna(method='pad', inplace=True) # 填充前一条数据的值，但是前一条也不一定有值\n",
    "# train_data.fillna(method='bfill', inplace=True) # 填充后一条数据的值，但是后一条也不一定有值\n",
    "\n",
    "# \"\"\"插值法：用插值法拟合出缺失的数据，然后进行填充。\"\"\"\n",
    "# for f in features: \n",
    "#     train_data[f] = train_data[f].interpolate()\n",
    "\n",
    "# train_data.dropna(inplace=True)\n",
    "\n",
    "# \"\"\"填充KNN数据：先利用knn计算临近的k个数据，然后填充他们的均值\"\"\"\n",
    "# from fancyimpute import KNN\n",
    "# train_data_x = pd.DataFrame(KNN(k=6).fit_transform(train_data_x), columns=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据分桶\n",
    "连续值经常离散化或者分离成“箱子”进行分析, 为什么要做数据分桶呢？\n",
    "\n",
    "离散后稀疏向量内积乘法运算速度更快，计算结果也方便存储，容易扩展；\n",
    "\n",
    "离散后的特征对异常值更具鲁棒性，如 age>30 为 1 否则为 0，对于年龄为 200 的也不会对模型造成很大的干扰； \n",
    "\n",
    "LR 属于广义线性模型，表达能力有限，经过离散化后，每个变量有单独的权重，这相当于引入了非线性，能够提升模型的表达能力，加大拟合；\n",
    "\n",
    "离散后特征可以进行特征交叉，提升表达能力，由 M+N 个变量编程 M*N 个变量，进一步引入非线形，提升了表达能力；\n",
    "\n",
    "特征离散后模型更稳定，如用户年龄区间，不会因为用户年龄长了一岁就变化\n",
    "\n",
    "\n",
    "\n",
    "当然还有很多原因，LightGBM 在改进 XGBoost 时就增加了数据分桶，增强了模型的泛化性。现在介绍数据分桶的方式：\n",
    "\n",
    "等频分桶\n",
    "\n",
    "等距分桶\n",
    "\n",
    "Best-KS分桶（类似利用基尼指数进行二分类）\n",
    "\n",
    "卡方分桶\n",
    "\n",
    "最好将数据分桶的特征作为新一列的特征，不要把原来的数据给替换掉, 所以在这里通过分桶的方式做一个特征出来看看，以power为例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin = [i*10 for i in range(31)]\n",
    "original_data['power_bin'] = pd.cut(original_data['power'], bin, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e38cd24af0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_data['power_bin'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据转换\n",
    "数据转换的方式有：\n",
    "\n",
    "数据归一化(MinMaxScaler)；\n",
    "\n",
    "标准化(StandardScaler)；\n",
    "\n",
    "对数变换(log1p)；\n",
    "\n",
    "转换数据类型(astype)；\n",
    "\n",
    "独热编码(OneHotEncoder)；\n",
    "\n",
    "标签编码(LabelEncoder)；\n",
    "\n",
    "修复偏斜特征(boxcox1p)等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 数值特征归一化， 因为这里数值的取值范围相差很大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax = MinMaxScaler()\n",
    "# num_data_minmax = minmax.fit_transform(num_data)\n",
    "# num_data_minmax = pd.DataFrame(num_data_minmax, columns=num_data.columns, index=num_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 类别特征独热一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"类别特征某些需要独热编码一下\"\"\"\n",
    "# hot_features = ['bodyType', 'fuelType', 'gearbox', 'notRepairedDamage']\n",
    "# cat_data_hot = pd.get_dummies(cat_data, columns=hot_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 关于高势集特征model，也就是类别中取值个数非常多的， 一般可以使用聚类的方式，然后独热，这里就采用了这种方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "# #from sklearn.cluster import AgglomerativeClustering\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# ac = KMeans(n_clusters=3)\n",
    "# ac.fit(model_price_data)\n",
    "\n",
    "# model_fea = ac.predict(model_price_data)\n",
    "# plt.scatter(model_price_data[:,0], model_price_data[:,1], c=model_fea)\n",
    "\n",
    "# cat_data_hot['model_fea'] = model_fea\n",
    "# cat_data_hot = pd.get_dummies(cat_data_hot, columns=['model_fea'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  特征构造\n",
    "在特征构造的时候，需要借助一些背景知识，遵循的一般原则就是需要发挥想象力，尽可能多的创造特征，不用先考虑哪些特征可能好，可能不好，先弥补这个广度。特征构造的时候需要考虑数值特征，类别特征，时间特征。\n",
    "\n",
    "对于数值特征，一般会尝试一些它们之间的加减组合（当然不要乱来，根据特征表达的含义）或者提取一些统计特征\n",
    "\n",
    "对于类别特征，我们一般会尝试之间的交叉组合，embedding也是一种思路\n",
    "\n",
    "对于时间特征，这一块又可以作为一个大专题来学习，在时间序列的预测中这一块非常重要，也会非常复杂，需要就尽可能多的挖掘时间信息，会有不同的方式技巧。当然在这个比赛中涉及的实际序列数据有一点点，不会那么复杂。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/p2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='p2.png', width=500, height=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src='p2.png', width=500, height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时间特征的构造(time_data)\n",
    "\n",
    "根据上面的分析，可以构造的时间特征如下：\n",
    "\n",
    "汽车的上线日期与汽车的注册日期之差就是汽车的使用时间，一般来说与价格成反比\n",
    "\n",
    "对汽车的使用时间进行分箱，使用了3年以下，3-7年，7-10年和10年以上，分为四个等级， 10年之后就是报废车了，应该会影响价格\n",
    "\n",
    "淡旺季也会影响价格，所以可以从汽车的上线日期上提取一下淡旺季信息\n",
    "\n",
    "\n",
    "\n",
    "汽车的使用时间特征\n",
    "\n",
    "createDate-regDate， 反应汽车使用时间，一般来说与价格成反比。但要注意的问题就是时间格式， regDateFalse这个字段有些是0月，如果忽略错误计算的话，使用时间有一些会是空值， 当然可以考虑删除这些空值，但是因为训练集和测试集合并了，那么就不轻易删除了。\n",
    "\n",
    "\n",
    "\n",
    "本文采取的办法是把错误字段都给他加1个月，然后计算出天数之后在加上30天（这个有不同的处理方式， 但是一般不喜欢删除或者置为空，因为删除和空值都有潜在的副作用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里是为了标记一下哪些字段有错误\n",
    "def regDateFalse(x):\n",
    "    if str(x)[4:6] == '00':\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "original_data['regDateFalse'] = original_data['regDate'].apply(lambda x: regDateFalse(x))\n",
    "# 这里是改正错误字段\n",
    "def changeFalse(x):\n",
    "    x = str(x)\n",
    "    if x[4:6] == '00':\n",
    "        x = x[0:4] + '01' + x[6:]\n",
    "        x = int(x)\n",
    "    return x\n",
    "original_data['regDate'] = original_data['regDate'].apply(lambda x: changeFalse(x))\n",
    "# 使用时间：data['creatDate'] - data['regDate']，反应汽车使用时间，一般来说价格与使用时间成反比\n",
    "# 不过要注意，数据里有时间出错的格式，所以我们需要 errors='coerce'\n",
    "original_data['used_time'] = (pd.to_datetime(original_data['creatDate'], format='%Y%m%d') - \n",
    "                            pd.to_datetime(original_data['regDate'], format='%Y%m%d')).dt.days\n",
    "# 修改错误\n",
    "# 但是需要加上那一个月\n",
    "original_data.loc[original_data.regDateFalse==1, 'used_time'] += 30\n",
    "# 删除标记列\n",
    "del original_data['regDateFalse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个特征构造完毕， used_time字段，表示汽车的使用时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "汽车是不是符合报废\n",
    "\n",
    "时间特征还可以继续提取，我们假设用了10年的车作为报废车的话， 那么我们可以根据使用天数计算出年数， 然后根据年数构造出一个特征是不是报废"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用时间换成年来表示\n",
    "original_data['used_time'] = original_data['used_time'] / 365.0\n",
    "original_data['Is_scrap'] = original_data['used_time'].apply(lambda x: 1 if x>=10 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 3, 7, 10, 20, 30]\n",
    "original_data['estivalue'] = pd.cut(original_data['used_time'], bins, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造了两个时间特征。Is_scrap表示是否报废， estivalue表示使用时间的分箱。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "是不是淡旺季\n",
    "\n",
    "这个是根据汽车的上线售卖时间看， 每年的2， 3月份及6,7,8月份是整个汽车行业的低谷， 年初和年末及9月份是二手车销售的黄金时期， 所以根据上线时间选出淡旺季。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选出淡旺季\n",
    "low_seasons = ['3', '6', '7', '8']\n",
    "original_data['is_low_seasons'] = original_data['creatDate'].apply(lambda x: 1 if str(x)[5] in low_seasons else 0)\n",
    "\n",
    "# 独热一下\n",
    "original_data = pd.get_dummies(original_data, columns=['is_low_seasons'])\n",
    "\n",
    "# 这样时间特征构造完毕，删除日期了\n",
    "del original_data['regDate']\n",
    "del original_data['creatDate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据汽车的使用时间或者淡旺季分桶进行统计特征的构造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类别特征的构造（cat_data）\n",
    "经过上面的分析，可以构造的类别特征如下：\n",
    "\n",
    "从邮编中提取城市信息， 因为是德国的数据，所以参考德国的邮编，加入先验知识， 但是感觉这个没有用，可以先试一下\n",
    "\n",
    "最好是从regioncode中提取出是不是华东地区，因为华东地区是二手车交易的主要地区（这个没弄出来，不知道这些编码到底指的哪跟哪）\n",
    "\n",
    "私用车和商用车分开（bodyType提取）\n",
    "\n",
    "是不是微型车单独处理，所以感觉那些车的类型OneHot的时候有点分散了（bodyType这个提取，然后one-hot）\n",
    "\n",
    "新能源车和燃油车分开（在fuelType中提取，然后进行OneHot）\n",
    "\n",
    "地区编码还是有影响的， 不同的地区汽车的保率不同\n",
    "\n",
    "品牌这块可以提取一些统计量， 统计特征的话上面这些新构造的特征其实也可以提取\n",
    "\n",
    "注意，OneHot不要太早，否则有些特征就没法提取潜在信息了。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择\n",
    "特征选择(排序)对于数据科学家、机器学习从业者来说非常重要。好的特征选择能够提升模型的性能，更能帮助我们理解数据的特点、底层结构，这对进一步改善模型、算法都有着重要作用。\n",
    "\n",
    "\n",
    "\n",
    "但是拿到数据集，一个特征选择方法，往往很难同时完成这两个目的。通常情况下，我们经常不管三七二十一，选择一种自己最熟悉或者最方便的特征选择方法（往往目的是降维，而忽略了对特征和数据理解的目的）, 但是真的好使吗？只能说具体问题具体分析，也许会暴力出奇迹呢。\n",
    "\n",
    "\n",
    "\n",
    "特征选择主要有两个功能：\n",
    "\n",
    "减少特征数量、降维，使模型泛化能力更强，减少过拟合\n",
    "\n",
    "增强对特征和特征值之间的理解\n",
    "\n",
    "\n",
    "\n",
    "通常来说，从两个方面考虑来选择特征：\n",
    "\n",
    "特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。\n",
    "\n",
    "特征与目标的相关性：这点比较显见，与目标相关性高的特征，应当优选选择。\n",
    "\n",
    "\n",
    "\n",
    "根据特征选择的形式又可以将特征选择方法分为3种：\n",
    "\n",
    "Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。\n",
    "\n",
    "Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。\n",
    "\n",
    "Embedded：嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过滤式\n",
    "\n",
    "主要思想: 对每一维特征“打分”，即给每一维的特征赋予权重，这样的权重就代表着该特征的重要性，然后依据权重排序。先进行特征选择，然后去训练学习器，所以特征选择的过程与学习器无关。相当于先对特征进行过滤操作，然后用特征子集来训练分类器。\n",
    "\n",
    "主要方法：\n",
    "\n",
    "移除低方差的特征；\n",
    "\n",
    "相关系数排序，分别计算每个特征与输出值之间的相关系数，设定一个阈值，选择相关系数大于阈值的部分特征；\n",
    "\n",
    "利用假设检验得到特征与输出值之间的相关性，方法有比如卡方检验、t检验、F检验等。\n",
    "\n",
    "互信息，利用互信息从信息熵的角度分析相关性。\n",
    "\n",
    "\n",
    "\n",
    "这里，本文为大家提供一些有价值的小tricks：\n",
    "\n",
    "对于数值型特征，方差很小的特征可以不要，因为太小没有什么区分度，提供不了太多的信息，对于分类特征，也是同理，取值个数高度偏斜的那种可以先去掉。\n",
    "\n",
    "根据与目标的相关性等选出比较相关的特征（当然有时候根据字段含义也可以选）\n",
    "\n",
    "卡方检验一般是检查离散变量与离散变量的相关性，当然离散变量的相关性信息增益和信息增益比也是不错的选择（可以通过决策树模型来评估来看），person系数一般是查看连续变量与连续变量的线性相关关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去掉取值变化小的特征\n",
    "\n",
    "这应该是最简单的特征选择方法了：假设某特征的特征值只有0和1，并且在所有输入样本中，95%的实例的该特征取值都是1，那就可以认为这个特征作用不大。如果100%都是1，那这个特征就没意义了。\n",
    "\n",
    "\n",
    "\n",
    "当特征值都是离散型变量的时候这种方法才能用，如果是连续型变量，就需要将连续变量离散化之后才能用，而且实际当中，一般不太会有95%以上都取某个值的特征存在，所以这种方法虽然简单但是不太好用。\n",
    "\n",
    "\n",
    "\n",
    "可以把它作为特征选择的预处理，先去掉那些取值变化小的特征，然后再从接下来提到的的特征选择方法中选择合适的进行进一步的特征选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单变量特征选择\n",
    "\n",
    "单变量特征选择能够对每一个特征进行测试，衡量该特征和响应变量之间的关系，根据得分扔掉不好的特征。对于回归和分类问题可以采用卡方检验等方式对特征进行测试。\n",
    "\n",
    "\n",
    "\n",
    "这种方法比较简单，易于运行，易于理解，通常对于理解数据有较好的效果（但对特征优化、提高泛化能力来说不一定有效）；这种方法有许多改进的版本、变种。\n",
    "\n",
    "\n",
    "\n",
    "下面重点介绍一下pearson相关系数，皮尔森相关系数是一种最简单的，比较常用的方式。能帮助理解特征和响应变量之间关系的方法，该方法衡量的是变量之间的线性相关性，结果的取值区间为[-1，1]，-1表示完全的负相关(这个变量下降，那个就会上升)，+1表示完全的正相关，0表示没有线性相关。\n",
    "\n",
    "\n",
    "\n",
    "Pearson Correlation速度快、易于计算，经常在拿到数据(经过清洗和特征提取之后的)之后第一时间就执行。Scipy的pearsonr方法能够同时计算相关系数和p-value, 当然pandas的corr也可以计算。\n",
    "\n",
    "\n",
    "\n",
    "直接根据pearson系数画出图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = original_data.corr('price')    # .corr('spearman')\n",
    "# plt.figure(figsize=(25, 15))\n",
    "# corr['price'].sort_values(ascending=False)[1:].plot(kind='bar')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，这个数据用pearson系数可能不是那么合理，可以使用spearman系数，这个被认为是排列后的变量的pearson的相关系数， 具体的可以看(Pearson)皮尔逊相关系数和spearman相关系数, 这里只整理两者的区别和使用场景, 区别如下：\n",
    "\n",
    "连续数据，正态分布，线性关系，用pearson相关系数是最恰当，当然用spearman相关系数也可以，效率没有pearson相关系数高。\n",
    "\n",
    "上述任一条件不满足，就用spearman相关系数，不能用pearson相关系数。\n",
    "\n",
    "两个定序测量数据（顺序变量）之间也用spearman相关系数，不能用pearson相关系数。\n",
    "\n",
    "Pearson相关系数的一个明显缺陷是，作为特征排序机制，他只对线性关系敏感。如果关系是非线性的，即便两个变量具有一一对应的关系，Pearson相关性也可能会接近0。\n",
    "\n",
    "\n",
    "\n",
    "当然还可以画出热力图来，这个不陌生了吧， 这个的目的是可以看变量之间的关系， 相关性大的，可以考虑保留其中一个："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面两个步骤中，就可以发现一些结论：\n",
    "\n",
    "根据与price的线性相关关系来看的话，我们可以考虑正负相关0.6以上的特征， v_std, v_12, v_0, v_8, estivalue_price_average, estivalue_price_median, estivalue_price_std， kil_bin, kilmoeter, estivalue_count, used_time, estivalue, v_3\n",
    "\n",
    "某些变量之间有很强的的关联性，比如v_mean和v_sum，这俩的相关性是1，所以可以删掉其中一个。\n",
    "\n",
    "当然，依然是备选删除选项和备选保留选项（这些都先别做）， 因为我们有时候不能盲目，就比如上面的相关性，明明知道pearson的缺陷是无法捕捉非线性相关，所以得出的这个结论也是片面的结论。这些都是备选，先做个心中有数，后面再用一些别的方式看看再说（如果现在就删除了，后面的方法就不好判断了）\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 包裹式\n",
    "\n",
    "单变量特征选择方法独立的衡量每个特征与响应变量之间的关系，另一种主流的特征选择方法是基于机器学习模型的方法。有些机器学习方法本身就具有对特征进行打分的机制，或者很容易将其运用到特征选择任务中，例如回归模型，SVM，决策树，随机森林等等。\n",
    "\n",
    "\n",
    "\n",
    "主要思想：包裹式从初始特征集合中不断的选择特征子集，训练学习器，根据学习器的性能来对子集进行评价，直到选择出最佳的子集。包裹式特征选择直接针对给定学习器进行优化。\n",
    "\n",
    "主要方法：递归特征消除算法, 基于机器学习模型的特征排序\n",
    "\n",
    "优缺点：\n",
    "\n",
    "优点：从最终学习器的性能来看，包裹式比过滤式更好；\n",
    "\n",
    "缺点：由于特征选择过程中需要多次训练学习器，因此包裹式特征选择的计算开销通常比过滤式特征选择要大得多。\n",
    "\n",
    "\n",
    "\n",
    "下面，这里整理基于学习模型的特征排序方法，这种方法的思路是直接使用你要用的机器学习算法，针对每个单独的特征和响应变量建立预测模型。其实Pearson相关系数等价于线性回归里的标准化回归系数。\n",
    "\n",
    "\n",
    "\n",
    "假如某个特征和响应变量之间的关系是非线性的，可以用基于树的方法（决策树、随机森林）、或者扩展的线性模型等。基于树的方法比较易于使用，因为他们对非线性关系的建模比较好，并且不需要太多的调试。但要注意过拟合问题，因此树的深度最好不要太大，再就是运用交叉验证。\n",
    "\n",
    "\n",
    "\n",
    "我们可以用随机森林来跑一下，看看随机森林比较喜欢特征："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = select_data.iloc[:, :-1]\n",
    "Y = select_data['price']\n",
    "names = select_data.columns\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=20, max_depth=4)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "scores = []\n",
    "for column in X.columns:\n",
    "    print(column)\n",
    "    tempx = X[column].values.reshape(-1, 1)\n",
    "    score = cross_val_score(rf, tempx, Y, scoring=\"r2\",\n",
    "                              cv=kfold)\n",
    "    scores.append((round(np.mean(score), 3), column))\n",
    "print(sorted(scores, reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  嵌入式\n",
    "\n",
    "在过滤式和包裹式特征选择方法中，特征选择过程与学习器训练过程有明显的分别。而嵌入式特征选择在学习器 训练过程中自动地进行特征选择。嵌入式选择最常用的是L1正则化与L2正则化。在对线性回归模型加入两种正则化方法后，他们分别变成了岭回归与Lasso回归。\n",
    "\n",
    "\n",
    "\n",
    "主要思想：在模型既定的情况下学习出对提高模型准确性最好的特征。也就是在确定模型的过程中，挑选出那些对模型的训练有重要意义的特征。\n",
    "\n",
    "主要方法：简单易学的机器学习算法–岭回归（Ridge Regression），就是线性回归过程加入了L2正则项。\n",
    "\n",
    "\n",
    "\n",
    "L1正则化有助于生成一个稀疏权值矩阵，进而可以用于特征选择\n",
    "\n",
    "\n",
    "\n",
    "L2正则化在拟合过程中通常都倾向于让权值尽可能小，最后构造一个所有参数都比较小的模型。因为一般认为参 数值小的模型比较简单，能适应不同的数据集，也在一定程度上避免了过拟合现象。可以设想一下对于一个线性 回归方程，若参数很大，那么只要数据偏移一点点，就会对结果造成很大的影响；但如果参数足够小，数据偏移 得多一点也不会对结果造成什么影响，专业一点的说法是『抗扰动能力强』\n",
    "\n",
    "\n",
    "\n",
    "这里简单介绍一下怎么使用，其实和上面机器学习模型的使用方法一样， 所以有时候这些方法没有必要严格的区分开："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA降维技术\n",
    "通过上面的特征选择部分，可以选出更好的分析特征，但是如果这些特征维度仍然很高怎么办？\n",
    "\n",
    "\n",
    "\n",
    "如果数据特征维度太高，首先计算很麻烦，其次增加了问题的复杂程度，分析起来也不方便。这时候就会想是不是再去掉一些特征就好了呢？但是这个特征也不是凭自己的意愿去掉的，因为盲目减少数据的特征会损失掉数据包含的关键信息，容易产生错误的结论，对分析不利。\n",
    "\n",
    "\n",
    "\n",
    "所以想找到一个合理的方式，既可以减少需要分析的指标，而且尽可能多的保持原来数据的信息，PCA就是这个合理的方式之一。 但要注意一点， 特征选择是从已存在的特征中选取携带信息最多的，选完之后的特征依然具有可解释性，而PCA，将已存在的特征压缩，降维完毕后不是原来特征的任何一个，也就是PCA降维之后的特征我们根本不知道什么含义了。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
